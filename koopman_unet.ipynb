{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:13:45.914834Z",
     "start_time": "2025-11-18T21:13:45.911043Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import DDPMScheduler, UNet2DModel, DDPMPipeline\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "from diffusers.models.embeddings import Timesteps, TimestepEmbedding\n",
    "from diffusers.models.unets.unet_2d_blocks import UNetMidBlock2D, get_down_block, get_up_block\n",
    "from dataclasses import dataclass\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bab6db26528cdb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:13:45.927983Z",
     "start_time": "2025-11-18T21:13:45.926404Z"
    }
   },
   "outputs": [],
   "source": [
    "KOOPMAN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "177893403fba2525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:13:45.940510Z",
     "start_time": "2025-11-18T21:13:45.938014Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    # Optimization\n",
    "    image_size = 32\n",
    "    train_batch_size = 64\n",
    "    eval_batch_size = 64\n",
    "    num_epochs = 20\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    save_image_epochs = 5\n",
    "    save_model_epochs = 10\n",
    "    seed = 0\n",
    "\n",
    "    # Dynamic Output Directory\n",
    "    output_dir = \"ddpm_mnist_koopman\" if KOOPMAN else \"ddpm_mnist_baseline\"\n",
    "\n",
    "    # Shared Architecture (Used by BOTH models for fair comparison)\n",
    "    in_channels = 1\n",
    "    out_channels = 1\n",
    "    block_out_channels = (32, 64, 128, 128)\n",
    "    layers_per_block = 2\n",
    "    down_block_types = (\"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\", \"DownBlock2D\")\n",
    "    up_block_types = (\"UpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\")\n",
    "    sample_size = image_size\n",
    "\n",
    "config = TrainingConfig()\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3343b356cb4a138b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:13:45.949167Z",
     "start_time": "2025-11-18T21:13:45.946774Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(config):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((config.image_size, config.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ])\n",
    "    dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=preprocess)\n",
    "    return DataLoader(dataset, batch_size=config.train_batch_size, shuffle=True)\n",
    "\n",
    "def save_sample(model, scheduler, epoch, config):\n",
    "    model.eval()\n",
    "    pipeline = DDPMPipeline(unet=model, scheduler=scheduler)\n",
    "    images = pipeline(batch_size=config.eval_batch_size, generator=torch.manual_seed(config.seed), num_inference_steps=50).images\n",
    "\n",
    "    # Convert to grid\n",
    "    grid = torchvision.utils.make_grid([transforms.ToTensor()(img) for img in images], nrow=8)\n",
    "    pil_grid = transforms.ToPILImage()(grid)\n",
    "    pil_grid.save(f\"{config.output_dir}/epoch_{epoch+1:04d}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6fed7ae-dc14-4ea4-8928-bac6044d4b71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:13:45.962142Z",
     "start_time": "2025-11-18T21:13:45.954603Z"
    }
   },
   "outputs": [],
   "source": [
    "class KoopmanUNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # 1. Time Embedding\n",
    "        time_embed_dim = config.block_out_channels[0] * 4\n",
    "        self.time_proj = Timesteps(config.block_out_channels[0], flip_sin_to_cos=True, downscale_freq_shift=0)\n",
    "        self.time_embedding = TimestepEmbedding(config.block_out_channels[0], time_embed_dim)\n",
    "\n",
    "        # 2. Pre-process\n",
    "        self.conv_in = nn.Conv2d(config.in_channels, config.block_out_channels[0], kernel_size=3, padding=1)\n",
    "\n",
    "        # 3. Down Blocks (Encoder)\n",
    "        self.down_blocks = nn.ModuleList([])\n",
    "        output_channel = config.block_out_channels[0]\n",
    "        for i, down_block_type in enumerate(config.down_block_types):\n",
    "            input_channel = output_channel\n",
    "            output_channel = config.block_out_channels[i]\n",
    "            is_final = i == len(config.down_block_types) - 1\n",
    "            \n",
    "            self.down_blocks.append(get_down_block(\n",
    "                down_block_type, \n",
    "                num_layers=config.layers_per_block, \n",
    "                in_channels=input_channel,\n",
    "                out_channels=output_channel, \n",
    "                temb_channels=time_embed_dim, \n",
    "                add_downsample=not is_final,\n",
    "                resnet_eps=1e-5,\n",
    "                resnet_act_fn=\"silu\",\n",
    "                resnet_groups=32, \n",
    "                attention_head_dim=8,\n",
    "                downsample_padding=1\n",
    "            ))\n",
    "\n",
    "        # 4. Mid Block\n",
    "        self.mid_block = UNetMidBlock2D(\n",
    "            in_channels=config.block_out_channels[-1], \n",
    "            temb_channels=time_embed_dim,\n",
    "            resnet_eps=1e-5,\n",
    "            resnet_act_fn=\"silu\",\n",
    "            resnet_groups=32, \n",
    "            attention_head_dim=8,\n",
    "            output_scale_factor=1\n",
    "        )\n",
    "\n",
    "        # 5. Koopman Bottleneck\n",
    "        self.bottleneck_c = config.block_out_channels[-1]\n",
    "        ds_factor = 2 ** (len(config.down_block_types) - 1)\n",
    "        self.bottleneck_h = config.image_size // ds_factor\n",
    "        self.bottleneck_w = config.image_size // ds_factor\n",
    "        features = self.bottleneck_c * self.bottleneck_h * self.bottleneck_w\n",
    "        \n",
    "        self.koopman_operator = nn.Linear(features, features)\n",
    "        print(f\"Koopman Operator initialized with {features} features.\")\n",
    "\n",
    "        # 6. Up Blocks (Decoder)\n",
    "        self.up_blocks = nn.ModuleList([])\n",
    "        reversed_ch = list(reversed(config.block_out_channels))\n",
    "        output_channel = reversed_ch[0]\n",
    "        for i, up_block_type in enumerate(config.up_block_types):\n",
    "            prev_output_channel = output_channel\n",
    "            output_channel = reversed_ch[i]\n",
    "            input_channel = reversed_ch[min(i + 1, len(config.block_out_channels) - 1)]\n",
    "            is_final = i == len(config.up_block_types) - 1\n",
    "\n",
    "            self.up_blocks.append(get_up_block(\n",
    "                up_block_type, \n",
    "                num_layers=config.layers_per_block + 1, \n",
    "                in_channels=input_channel,\n",
    "                out_channels=output_channel, \n",
    "                prev_output_channel=prev_output_channel,\n",
    "                temb_channels=time_embed_dim, \n",
    "                add_upsample=not is_final,\n",
    "                resnet_eps=1e-5,\n",
    "                resnet_act_fn=\"silu\",\n",
    "                resnet_groups=32, \n",
    "                attention_head_dim=8\n",
    "            ))\n",
    "            prev_output_channel = output_channel\n",
    "\n",
    "        # 7. Output\n",
    "        self.conv_norm_out = nn.GroupNorm(32, config.block_out_channels[0], eps=1e-5)\n",
    "        self.conv_act = nn.SiLU()\n",
    "        self.conv_out = nn.Conv2d(config.block_out_channels[0], config.out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        \"\"\"Helper for Diffusers pipeline compatibility.\"\"\"\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        \"\"\"Helper for Diffusers pipeline compatibility.\"\"\"\n",
    "        return next(self.parameters()).dtype\n",
    "\n",
    "    def forward(self, x, t, return_dict=False):\n",
    "        # Handle Time\n",
    "        t = t.to(x.device)\n",
    "        if t.dim() == 0: t = t.unsqueeze(0).expand(x.shape[0])\n",
    "        t_emb = self.time_embedding(self.time_proj(t))\n",
    "\n",
    "        # Encoder\n",
    "        x = self.conv_in(x)\n",
    "        skips = (x,)\n",
    "        for block in self.down_blocks:\n",
    "            x, s = block(x, t_emb)\n",
    "            skips += s\n",
    "        \n",
    "        # Mid & Koopman\n",
    "        x = self.mid_block(x, t_emb)\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # Use reshape() instead of view() to handle non-contiguous memory\n",
    "        x = self.koopman_operator(x.reshape(B, -1)).reshape(B, C, H, W)\n",
    "\n",
    "        # Decoder\n",
    "        for block in self.up_blocks:\n",
    "            res_skips = skips[-len(block.resnets):]\n",
    "            skips = skips[:-len(block.resnets)]\n",
    "            x = block(x, res_skips, temb=t_emb)\n",
    "\n",
    "        # Output\n",
    "        x = self.conv_out(self.conv_act(self.conv_norm_out(x)))\n",
    "        \n",
    "        if return_dict: return {\"sample\": x}\n",
    "        from diffusers.utils import BaseOutput\n",
    "        return BaseOutput(sample=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5bdd8c4be866dfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:13:45.968461Z",
     "start_time": "2025-11-18T21:13:45.966732Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(config, use_koopman=True):\n",
    "    \"\"\"\n",
    "    Returns either the Custom KoopmanUNet or the Standard Diffusers UNet2DModel\n",
    "    based on the boolean flag, ensuring identical architecture settings.\n",
    "    \"\"\"\n",
    "    if use_koopman:\n",
    "        print(f\"Initializing Custom KoopmanUNet (Rank constrained bottleneck)...\")\n",
    "        return KoopmanUNet(config)\n",
    "\n",
    "    else:\n",
    "        print(f\"Initializing Standard Baseline UNet2DModel...\")\n",
    "        return UNet2DModel(\n",
    "            sample_size=config.image_size,\n",
    "            in_channels=config.in_channels,\n",
    "            out_channels=config.out_channels,\n",
    "            layers_per_block=config.layers_per_block,\n",
    "            block_out_channels=config.block_out_channels,\n",
    "            down_block_types=config.down_block_types,\n",
    "            up_block_types=config.up_block_types,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b16db34a469e1f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:13:45.975913Z",
     "start_time": "2025-11-18T21:13:45.973237Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    # get the correct model\n",
    "    model = get_model(config, use_koopman=KOOPMAN).to(device)\n",
    "\n",
    "    # standard Setup\n",
    "    scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    dataloader = get_dataloader(config)\n",
    "    lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer, config.lr_warmup_steps, len(dataloader) * config.num_epochs\n",
    "    )\n",
    "\n",
    "    print(f\"--- Starting Training: {config.output_dir} ---\")\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        model.train()\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.num_epochs}\")\n",
    "        losses = []\n",
    "\n",
    "        for x, _ in pbar:\n",
    "            x = x.to(device)\n",
    "            noise = torch.randn_like(x)\n",
    "            t = torch.randint(0, 1000, (x.shape[0],), device=device).long()\n",
    "            noisy_x = scheduler.add_noise(x, noise, t)\n",
    "\n",
    "            # Diffusers UNet returns a tuple or object depending on return_dict,\n",
    "            # we unify this here\n",
    "            if KOOPMAN:\n",
    "                noise_pred = model(noisy_x, t).sample\n",
    "            else:\n",
    "                noise_pred = model(noisy_x, t).sample\n",
    "\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            pbar.set_postfix(loss=np.mean(losses[-100:]))\n",
    "\n",
    "        # save images/models\n",
    "        if (epoch + 1) % config.save_image_epochs == 0 or epoch == config.num_epochs - 1:\n",
    "            save_sample(model, scheduler, epoch, config)\n",
    "\n",
    "        if (epoch + 1) % config.save_model_epochs == 0:\n",
    "            # handle saving differently for diffusers model vs ours\n",
    "            save_path = f\"{config.output_dir}/model.pth\"\n",
    "            if hasattr(model, \"save_pretrained\") and not KOOPMAN:\n",
    "                 model.save_pretrained(config.output_dir) \n",
    "            else:\n",
    "                 torch.save(model.state_dict(), save_path) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b55962025d7cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:14:31.890563Z",
     "start_time": "2025-11-18T21:13:45.980547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Custom KoopmanUNet (Rank constrained bottleneck)...\n",
      "Koopman Operator initialized with 2048 features.\n",
      "--- Starting Training: ddpm_mnist_koopman ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d247204d834a49c1a47a0ec9166fded6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a153d1f8cdf8446ca11288395ea30ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2fab76ce3b4412bfe74dcdc929b388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789b5db6ee7249dfb7770a4be67ce5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e81dcb9662f4212acd94e2cf1519a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339c4cb398364ef399207594f1c9b5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cecc7d24659489192106e751123f030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11266f512a20416491f072e05ad190ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc82ae7013e470a83b154483fd0acad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb305e4f5d74e999f57c48196149c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e8e21b868d4a21af19ff201c0420f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1552ab1c7d37401580245b55dad52a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1244e8981746cab42334b9350ab185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f533e8c9bb154c0bb8ed67cbeb944c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daca62e17e334811b480a39c8ceade54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a264c480f2424a9aeb04f81fa651b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2690be2e4e8d4526ae81dc69a8f951af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623510f1d67bcbaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:14:31.898245Z",
     "start_time": "2025-11-18T14:31:01.554716Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:136: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:144: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:201: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:136: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:144: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:201: SyntaxWarning: invalid escape sequence '\\l'\n",
      "/var/folders/7q/d3z58krn1slbn5fckpc1y7jm0000gn/T/ipykernel_92986/3642555506.py:136: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  ax1.set_title(\"Eigenvalues $\\lambda$ in Complex Plane\", fontsize=16)\n",
      "/var/folders/7q/d3z58krn1slbn5fckpc1y7jm0000gn/T/ipykernel_92986/3642555506.py:144: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  ax2.set_ylabel(\"Magnitude $|\\lambda|$\")\n",
      "/var/folders/7q/d3z58krn1slbn5fckpc1y7jm0000gn/T/ipykernel_92986/3642555506.py:201: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  axs[i].set_title(f\"Mode {i}\\n$|\\lambda|={np.abs(eigenvalues[mode_index]):.3f}$\")\n"
     ]
    }
   ],
   "source": [
    "def analyze_koopman(model):\n",
    "    model.eval()\n",
    "    print(\"--- Analyzing Koopman Operator ---\")\n",
    "\n",
    "    # Extract K matrix\n",
    "    K = model.koopman_operator.weight.detach().cpu().numpy()\n",
    "\n",
    "    # 1. Singular Values (Rank)\n",
    "    U, S, Vh = np.linalg.svd(K)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(S[:100], 'o-') # Top 100\n",
    "    plt.yscale('log')\n",
    "    plt.title(\"Singular Values of K (Top 100)\")\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Eigenvalues (Dynamics)\n",
    "    eigenvalues, _ = np.linalg.eig(K)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.add_patch(plt.Circle((0, 0), 1, color='r', fill=False, ls='--'))\n",
    "    plt.scatter(eigenvalues.real, eigenvalues.imag, alpha=0.5, s=10)\n",
    "    plt.title(\"Eigenvalues in Complex Plane\")\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "# Load model if skipping training\n",
    "# model = KoopmanUNet(config)\n",
    "# model.load_state_dict(torch.load(f\"{config.output_dir}/model.pth\", map_location=device))\n",
    "analyze_koopman(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
