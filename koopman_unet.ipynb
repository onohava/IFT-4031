{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:09.522967Z",
     "start_time": "2025-11-18T22:57:09.519927Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import DDPMScheduler, UNet2DModel, DDPMPipeline\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "from diffusers.models.embeddings import Timesteps, TimestepEmbedding\n",
    "from diffusers.models.unets.unet_2d_blocks import UNetMidBlock2D, get_down_block, get_up_block\n",
    "from dataclasses import dataclass\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "6bab6db26528cdb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:09.907829Z",
     "start_time": "2025-11-18T22:57:09.905806Z"
    }
   },
   "source": [
    "KOOPMAN = False"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "177893403fba2525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:10.291561Z",
     "start_time": "2025-11-18T22:57:10.287521Z"
    }
   },
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    # Optimization\n",
    "    image_size = 32\n",
    "    train_batch_size = 64\n",
    "    eval_batch_size = 64\n",
    "    num_epochs = 20\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    save_image_epochs = 5\n",
    "    save_model_epochs = 10\n",
    "    seed = 0\n",
    "\n",
    "    # Dynamic Output Directory\n",
    "    output_dir = \"ddpm_mnist_koopman\" if KOOPMAN else \"ddpm_mnist_baseline\"\n",
    "\n",
    "    # Shared Architecture (Used by BOTH models for fair comparison)\n",
    "    in_channels = 1\n",
    "    out_channels = 1\n",
    "    block_out_channels = (32, 64, 128, 128)\n",
    "    layers_per_block = 2\n",
    "    down_block_types = (\"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\", \"DownBlock2D\")\n",
    "    up_block_types = (\"UpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\")\n",
    "    sample_size = image_size\n",
    "\n",
    "config = TrainingConfig()\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "3343b356cb4a138b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:11.768043Z",
     "start_time": "2025-11-18T22:57:11.765450Z"
    }
   },
   "source": [
    "def get_dataloader(config):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((config.image_size, config.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ])\n",
    "    dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=preprocess)\n",
    "    return DataLoader(dataset, batch_size=config.train_batch_size, shuffle=True)\n",
    "\n",
    "def save_sample(model, scheduler, epoch, config):\n",
    "    model.eval()\n",
    "    pipeline = DDPMPipeline(unet=model, scheduler=scheduler)\n",
    "    images = pipeline(batch_size=config.eval_batch_size, generator=torch.manual_seed(config.seed), num_inference_steps=50).images\n",
    "\n",
    "    # Convert to grid\n",
    "    grid = torchvision.utils.make_grid([transforms.ToTensor()(img) for img in images], nrow=8)\n",
    "    pil_grid = transforms.ToPILImage()(grid)\n",
    "    pil_grid.save(f\"{config.output_dir}/epoch_{epoch+1:04d}.png\")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "c6fed7ae-dc14-4ea4-8928-bac6044d4b71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:12.386221Z",
     "start_time": "2025-11-18T22:57:12.376860Z"
    }
   },
   "source": [
    "class KoopmanUNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # 1. Time Embedding\n",
    "        time_embed_dim = config.block_out_channels[0] * 4\n",
    "        self.time_proj = Timesteps(config.block_out_channels[0], flip_sin_to_cos=True, downscale_freq_shift=0)\n",
    "        self.time_embedding = TimestepEmbedding(config.block_out_channels[0], time_embed_dim)\n",
    "\n",
    "        # 2. Pre-process\n",
    "        self.conv_in = nn.Conv2d(config.in_channels, config.block_out_channels[0], kernel_size=3, padding=1)\n",
    "\n",
    "        # 3. Down Blocks (Encoder)\n",
    "        self.down_blocks = nn.ModuleList([])\n",
    "        output_channel = config.block_out_channels[0]\n",
    "        for i, down_block_type in enumerate(config.down_block_types):\n",
    "            input_channel = output_channel\n",
    "            output_channel = config.block_out_channels[i]\n",
    "            is_final = i == len(config.down_block_types) - 1\n",
    "            \n",
    "            self.down_blocks.append(get_down_block(\n",
    "                down_block_type, \n",
    "                num_layers=config.layers_per_block, \n",
    "                in_channels=input_channel,\n",
    "                out_channels=output_channel, \n",
    "                temb_channels=time_embed_dim, \n",
    "                add_downsample=not is_final,\n",
    "                resnet_eps=1e-5,\n",
    "                resnet_act_fn=\"silu\",\n",
    "                resnet_groups=32, \n",
    "                attention_head_dim=8,\n",
    "                downsample_padding=1\n",
    "            ))\n",
    "\n",
    "        # 4. Mid Block\n",
    "        self.mid_block = UNetMidBlock2D(\n",
    "            in_channels=config.block_out_channels[-1], \n",
    "            temb_channels=time_embed_dim,\n",
    "            resnet_eps=1e-5,\n",
    "            resnet_act_fn=\"silu\",\n",
    "            resnet_groups=32, \n",
    "            attention_head_dim=8,\n",
    "            output_scale_factor=1\n",
    "        )\n",
    "\n",
    "        # 5. Koopman Bottleneck\n",
    "        self.bottleneck_c = config.block_out_channels[-1]\n",
    "        ds_factor = 2 ** (len(config.down_block_types) - 1)\n",
    "        self.bottleneck_h = config.image_size // ds_factor\n",
    "        self.bottleneck_w = config.image_size // ds_factor\n",
    "        features = self.bottleneck_c * self.bottleneck_h * self.bottleneck_w\n",
    "        \n",
    "        self.koopman_operator = nn.Linear(features, features)\n",
    "        print(f\"Koopman Operator initialized with {features} features.\")\n",
    "\n",
    "        # 6. Up Blocks (Decoder)\n",
    "        self.up_blocks = nn.ModuleList([])\n",
    "        reversed_ch = list(reversed(config.block_out_channels))\n",
    "        output_channel = reversed_ch[0]\n",
    "        for i, up_block_type in enumerate(config.up_block_types):\n",
    "            prev_output_channel = output_channel\n",
    "            output_channel = reversed_ch[i]\n",
    "            input_channel = reversed_ch[min(i + 1, len(config.block_out_channels) - 1)]\n",
    "            is_final = i == len(config.up_block_types) - 1\n",
    "\n",
    "            self.up_blocks.append(get_up_block(\n",
    "                up_block_type, \n",
    "                num_layers=config.layers_per_block + 1, \n",
    "                in_channels=input_channel,\n",
    "                out_channels=output_channel, \n",
    "                prev_output_channel=prev_output_channel,\n",
    "                temb_channels=time_embed_dim, \n",
    "                add_upsample=not is_final,\n",
    "                resnet_eps=1e-5,\n",
    "                resnet_act_fn=\"silu\",\n",
    "                resnet_groups=32, \n",
    "                attention_head_dim=8\n",
    "            ))\n",
    "            prev_output_channel = output_channel\n",
    "\n",
    "        # 7. Output\n",
    "        self.conv_norm_out = nn.GroupNorm(32, config.block_out_channels[0], eps=1e-5)\n",
    "        self.conv_act = nn.SiLU()\n",
    "        self.conv_out = nn.Conv2d(config.block_out_channels[0], config.out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        \"\"\"Helper for Diffusers pipeline compatibility.\"\"\"\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        \"\"\"Helper for Diffusers pipeline compatibility.\"\"\"\n",
    "        return next(self.parameters()).dtype\n",
    "\n",
    "    def forward(self, x, t, return_dict=False):\n",
    "        # Handle Time\n",
    "        t = t.to(x.device)\n",
    "        if t.dim() == 0: t = t.unsqueeze(0).expand(x.shape[0])\n",
    "        t_emb = self.time_embedding(self.time_proj(t))\n",
    "\n",
    "        # Encoder\n",
    "        x = self.conv_in(x)\n",
    "        skips = (x,)\n",
    "        for block in self.down_blocks:\n",
    "            x, s = block(x, t_emb)\n",
    "            skips += s\n",
    "        \n",
    "        # Mid & Koopman\n",
    "        x = self.mid_block(x, t_emb)\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # Use reshape() instead of view() to handle non-contiguous memory\n",
    "        x = self.koopman_operator(x.reshape(B, -1)).reshape(B, C, H, W)\n",
    "\n",
    "        # Decoder\n",
    "        for block in self.up_blocks:\n",
    "            res_skips = skips[-len(block.resnets):]\n",
    "            skips = skips[:-len(block.resnets)]\n",
    "            x = block(x, res_skips, temb=t_emb)\n",
    "\n",
    "        # Output\n",
    "        x = self.conv_out(self.conv_act(self.conv_norm_out(x)))\n",
    "        \n",
    "        if return_dict: return {\"sample\": x}\n",
    "        from diffusers.utils import BaseOutput\n",
    "        return BaseOutput(sample=x)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "f5bdd8c4be866dfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:13.410170Z",
     "start_time": "2025-11-18T22:57:13.407176Z"
    }
   },
   "source": [
    "def get_model(config, use_koopman=True):\n",
    "    \"\"\"\n",
    "    Returns either the Custom KoopmanUNet or the Standard Diffusers UNet2DModel\n",
    "    based on the boolean flag, ensuring identical architecture settings.\n",
    "    \"\"\"\n",
    "    if use_koopman:\n",
    "        print(f\"Initializing Custom KoopmanUNet (Rank constrained bottleneck)...\")\n",
    "        return KoopmanUNet(config)\n",
    "\n",
    "    else:\n",
    "        print(f\"Initializing Standard Baseline UNet2DModel...\")\n",
    "        return UNet2DModel(\n",
    "            sample_size=config.image_size,\n",
    "            in_channels=config.in_channels,\n",
    "            out_channels=config.out_channels,\n",
    "            layers_per_block=config.layers_per_block,\n",
    "            block_out_channels=config.block_out_channels,\n",
    "            down_block_types=config.down_block_types,\n",
    "            up_block_types=config.up_block_types,\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "b16db34a469e1f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:14.446535Z",
     "start_time": "2025-11-18T22:57:14.441591Z"
    }
   },
   "source": [
    "def train(config):\n",
    "    # get the correct model using the Toggle\n",
    "    model = get_model(config, use_koopman=KOOPMAN).to(device)\n",
    "\n",
    "    # standard Setup\n",
    "    scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    dataloader = get_dataloader(config)\n",
    "    lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer, config.lr_warmup_steps, len(dataloader) * config.num_epochs\n",
    "    )\n",
    "\n",
    "    print(f\"--- Starting Training: {config.output_dir} ---\")\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        model.train()\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.num_epochs}\")\n",
    "        losses = []\n",
    "\n",
    "        for x, _ in pbar:\n",
    "            x = x.to(device)\n",
    "            noise = torch.randn_like(x)\n",
    "            t = torch.randint(0, 1000, (x.shape[0],), device=device).long()\n",
    "            noisy_x = scheduler.add_noise(x, noise, t)\n",
    "\n",
    "            # Diffusers UNet returns a tuple or object depending on return_dict\n",
    "            # We unify this here:\n",
    "            if KOOPMAN:\n",
    "                noise_pred = model(noisy_x, t).sample\n",
    "            else:\n",
    "                noise_pred = model(noisy_x, t).sample\n",
    "\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            pbar.set_postfix(loss=np.mean(losses[-100:]))\n",
    "\n",
    "        # save images/models\n",
    "        if (epoch + 1) % config.save_image_epochs == 0 or epoch == config.num_epochs - 1:\n",
    "            save_sample(model, scheduler, epoch, config)\n",
    "\n",
    "        if (epoch + 1) % config.save_model_epochs == 0:\n",
    "            # handle saving differently for diffusers model vs ours\n",
    "            save_path = f\"{config.output_dir}/model.pth\"\n",
    "            if hasattr(model, \"save_pretrained\") and not KOOPMAN:\n",
    "                 model.save_pretrained(config.output_dir) \n",
    "            else:\n",
    "                 torch.save(model.state_dict(), save_path) \n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "809b55962025d7cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:14:31.890563Z",
     "start_time": "2025-11-18T21:13:45.980547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Custom KoopmanUNet (Rank constrained bottleneck)...\n",
      "Koopman Operator initialized with 2048 features.\n",
      "--- Starting Training: ddpm_mnist_koopman ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d247204d834a49c1a47a0ec9166fded6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a153d1f8cdf8446ca11288395ea30ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2fab76ce3b4412bfe74dcdc929b388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789b5db6ee7249dfb7770a4be67ce5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e81dcb9662f4212acd94e2cf1519a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339c4cb398364ef399207594f1c9b5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cecc7d24659489192106e751123f030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11266f512a20416491f072e05ad190ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc82ae7013e470a83b154483fd0acad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb305e4f5d74e999f57c48196149c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e8e21b868d4a21af19ff201c0420f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1552ab1c7d37401580245b55dad52a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1244e8981746cab42334b9350ab185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f533e8c9bb154c0bb8ed67cbeb944c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daca62e17e334811b480a39c8ceade54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a264c480f2424a9aeb04f81fa651b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2690be2e4e8d4526ae81dc69a8f951af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaef09dfd1f41f086f3997269a93f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ff8b514cb045399e031d10e0769a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0dafd3d8496492aa18b831a7ba600f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdbb9ea712240b393edca99d7ab959d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4043c13e082c4131a0f02e2af73c90b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbf128673e3455190b7e99ec6cbc217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4104aeffd5944327bc4ea52e0af3fa9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8dbd92b3-f481-4088-8dbe-69802de77911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Standard Baseline UNet2DModel...\n",
      "--- Starting Training: ddpm_mnist_baseline ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8248485cd8074cb391f58c8100511d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798ec6e5196f459abd8fc1dea88e650b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147c052506584469aeb7cf58cffd2ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e313dc3657400b9d00e6174df44baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08afe87c91d45e7ae4ea915e4a55102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea41bcbede5345f5bb58a064298f28b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd213728d6c947718eb4f353e1618588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ad220aef1344a3b5fc2947f79d585c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2940852400024c10a84f7972f6ee3143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e07f82b0164edfa16e0f331b4deea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f72924f94a4d2abfc77af43bb2f68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9b1282708e4203906298dfd3abb819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3f676a7231476887ec3c270456f673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5493a2812c4a73a9732f8dfa15b183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79e0ca9080e4189a9fc1c161e8f23d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720a6144127b4a7d8df1ea601bf7aaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4387860120456fb60a0bb958012d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc84dee2f54434692bcc7b99fadcb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f8ac4a1c104364b727d69115d3c979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7dd60db68b47a787ad4baa101625f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfbd73c35744fe4a20c86f6dbb71df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b81d5d12cf48f3bc84dac479a4c7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f582f2bad9134a3e812268b6015fced0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30e6b2b68d2475d8ec2f25b001a05fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_model = train(config)"
   ]
  },
  {
   "cell_type": "code",
   "id": "623510f1d67bcbaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:19.906097Z",
     "start_time": "2025-11-18T22:57:19.343002Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import warnings\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "def get_latent_vectors(model, dataloader, device, limit_batches=20):\n",
    "    \"\"\"\n",
    "    Extracts bottleneck vectors from a model for a subset of data.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "    \n",
    "    # Fixed timestep for consistent encoding\n",
    "    t = torch.tensor([500], device=device).long()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            if i >= limit_batches: break\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # Handle Time Embedding\n",
    "            t_batch = t.expand(x.shape[0])\n",
    "            t_emb = model.time_embedding(model.time_proj(t_batch))\n",
    "            \n",
    "            # Encoder Pass\n",
    "            h = model.conv_in(x)\n",
    "            for block in model.down_blocks:\n",
    "                h, _ = block(h, t_emb)\n",
    "            h = model.mid_block(h, t_emb)\n",
    "            \n",
    "            # Flatten to latent vector\n",
    "            vec = h.reshape(x.shape[0], -1)\n",
    "            latents.append(vec.cpu().numpy())\n",
    "            labels.append(y.numpy())\n",
    "            \n",
    "    return np.concatenate(latents), np.concatenate(labels)\n",
    "\n",
    "def plot_spectral_analysis(model, output_dir=\".\"):\n",
    "    \"\"\"\n",
    "    Generates Singular Value and Eigenvalue plots for the Koopman Operator.\n",
    "    Saves: koopman_singular_values.png, koopman_eigenvalues.png\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Spectral Analysis ---\")\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract the matrix K\n",
    "    # Assumes model.koopman_operator is an nn.Linear layer\n",
    "    K = model.koopman_operator.weight.detach().cpu().numpy()\n",
    "    \n",
    "    # 1. Singular Value Decomposition (Rank Analysis)\n",
    "    U, S, Vh = np.linalg.svd(K)\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(S, 'o-', color='#1f77b4', markersize=4, linewidth=1.5)\n",
    "    plt.yscale('log')\n",
    "    plt.title(r\"Singular Values of Operator $K$\", fontsize=16)\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(r\"Singular Value $\\sigma$ (Log Scale)\")\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/koopman_singular_values.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Eigenvalue Spectrum (Stability Analysis)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(K)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Unit Circle\n",
    "    circle = plt.Circle((0, 0), 1, color='black', fill=False, linestyle='--', linewidth=2, label=\"Unit Circle\")\n",
    "    ax.add_patch(circle)\n",
    "    \n",
    "    # Plot Eigenvalues\n",
    "    plt.scatter(eigenvalues.real, eigenvalues.imag, alpha=0.6, color='#d62728', s=30)\n",
    "    \n",
    "    plt.title(r\"Eigenvalues $\\lambda$ in Complex Plane\", fontsize=16)\n",
    "    plt.xlabel(\"Real Part\")\n",
    "    plt.ylabel(\"Imaginary Part\")\n",
    "    plt.axis('equal')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, ls=\":\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/koopman_eigenvalues.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "def plot_koopman_modes(model, config, device, eigenvalues, eigenvectors, output_dir=\".\"):\n",
    "    \"\"\"\n",
    "    Visualizes the top Koopman Modes by decoding eigenvectors.\n",
    "    Saves: koopman_modes.png\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Koopman Modes ---\")\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Get Dummy Skip Connections\n",
    "    # The decoder needs skip connections. We generate \"background\" skips \n",
    "    # by passing a zero tensor through the encoder.\n",
    "    dummy_input = torch.zeros(1, config.in_channels, config.image_size, config.image_size).to(device)\n",
    "    t = torch.tensor([500], device=device).long()\n",
    "    t_emb = model.time_embedding(model.time_proj(t))\n",
    "    \n",
    "    dummy_skips = []\n",
    "    with torch.no_grad():\n",
    "        x = model.conv_in(dummy_input)\n",
    "        dummy_skips.append(x)\n",
    "        for block in model.down_blocks:\n",
    "            x, skips = block(x, t_emb)\n",
    "            dummy_skips.extend(skips)\n",
    "    \n",
    "    # 2. Sort Eigenvectors by Magnitude\n",
    "    sorted_indices = np.argsort(np.abs(eigenvalues))[::-1]\n",
    "    \n",
    "    # 3. Decode Top Modes\n",
    "    num_modes = 8\n",
    "    modes_to_plot = []\n",
    "    \n",
    "    for i in range(num_modes):\n",
    "        idx = sorted_indices[i]\n",
    "        vec = eigenvectors[:, idx].real # Take real part for visualization\n",
    "        \n",
    "        # Prepare latent tensor\n",
    "        z = torch.from_numpy(vec).float().to(device)\n",
    "        z = z.reshape(1, model.bottleneck_c, model.bottleneck_h, model.bottleneck_w)\n",
    "        \n",
    "        # Decode\n",
    "        with torch.no_grad():\n",
    "            # We must copy the skips list because .pop() is destructive\n",
    "            current_skips = [s.clone() for s in dummy_skips]\n",
    "            \n",
    "            x_dec = z\n",
    "            for block in model.up_blocks:\n",
    "                # Get correct number of skips for this block (usually 2 or 3)\n",
    "                num_resnets = len(block.resnets)\n",
    "                skips_for_block = current_skips[-num_resnets:]\n",
    "                current_skips = current_skips[:-num_resnets]\n",
    "                \n",
    "                x_dec = block(x_dec, tuple(skips_for_block), temb=t_emb)\n",
    "            \n",
    "            out = model.conv_out(model.conv_act(model.conv_norm_out(x_dec)))\n",
    "            \n",
    "        # Normalize for display\n",
    "        img = out.squeeze().cpu().numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        modes_to_plot.append(img)\n",
    "\n",
    "    # 4. Plot Grid\n",
    "    fig = plt.figure(figsize=(16, 3))\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=(1, num_modes), axes_pad=0.1)\n",
    "    \n",
    "    for ax, img, i in zip(grid, modes_to_plot, range(num_modes)):\n",
    "        ax.imshow(img, cmap='viridis') # Viridis is good for abstract modes\n",
    "        ax.set_title(f\"Mode {i+1}\\n$|\\lambda|={np.abs(eigenvalues[sorted_indices[i]]):.2f}$\", fontsize=10)\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.savefig(f\"{output_dir}/koopman_modes.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_latent_comparison(koopman_model, baseline_model, dataloader, device, output_dir=\".\"):\n",
    "    \"\"\"\n",
    "    Comparing latent spaces using t-SNE.\n",
    "    Saves: koopman_tsne_comparison.png\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Latent Space Comparison ---\")\n",
    "    \n",
    "    # 1. Get Latents\n",
    "    print(\"Extracting Koopman latents...\")\n",
    "    k_vecs, k_labels = get_latent_vectors(koopman_model, dataloader, device)\n",
    "    \n",
    "    print(\"Extracting Baseline latents...\")\n",
    "    # Note: baseline_model must be on device\n",
    "    baseline_model.to(device)\n",
    "    b_vecs, b_labels = get_latent_vectors(baseline_model, dataloader, device)\n",
    "    \n",
    "    # 2. PCA (Pre-reduction for speed/stability)\n",
    "    pca = PCA(n_components=50)\n",
    "    k_pca = pca.fit_transform(k_vecs)\n",
    "    b_pca = pca.fit_transform(b_vecs)\n",
    "    \n",
    "    # 3. t-SNE\n",
    "    print(\"Running t-SNE...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "    k_tsne = tsne.fit_transform(k_pca)\n",
    "    b_tsne = tsne.fit_transform(b_pca)\n",
    "    \n",
    "    # 4. Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    # Koopman Plot\n",
    "    sns.scatterplot(x=k_tsne[:,0], y=k_tsne[:,1], hue=k_labels, palette=\"tab10\", ax=ax1, s=50, alpha=0.7, legend=False)\n",
    "    ax1.set_title(\"Koopman U-Net Latent Space\", fontsize=16)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Baseline Plot\n",
    "    sns.scatterplot(x=b_tsne[:,0], y=b_tsne[:,1], hue=b_labels, palette=\"tab10\", ax=ax2, s=50, alpha=0.7)\n",
    "    ax2.set_title(\"Standard U-Net Latent Space\", fontsize=16)\n",
    "    ax2.axis('off')\n",
    "    ax2.legend(title=\"Digit Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/koopman_tsne_comparison.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def run_full_dashboard(koopman_model, baseline_model, dataloader, config, device):\n",
    "    \"\"\"Orchestrates the full analysis suite.\"\"\"\n",
    "    # 1. Spectral\n",
    "    evals, evecs = plot_spectral_analysis(koopman_model)\n",
    "    \n",
    "    # 2. Modes\n",
    "    plot_koopman_modes(koopman_model, config, device, evals, evecs)\n",
    "    \n",
    "    # 3. Comparison \n",
    "    if baseline_model is not None:\n",
    "\n",
    "        plot_latent_comparison(koopman_model, baseline_model, dataloader, device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:160: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:160: SyntaxWarning: invalid escape sequence '\\l'\n",
      "/var/folders/7q/d3z58krn1slbn5fckpc1y7jm0000gn/T/ipykernel_25192/1603423301.py:160: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  ax.set_title(f\"Mode {i+1}\\n$|\\lambda|={np.abs(eigenvalues[sorted_indices[i]]):.2f}$\", fontsize=10)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T23:04:13.545960Z",
     "start_time": "2025-11-18T23:04:13.476989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading Koopman Model\n",
    "model = KoopmanUNet(config)\n",
    "state_dict = torch.load(\"ddpm_mnist_koopman/model.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Loading Baseline\n",
    "baseline_model = UNet2DModel.from_pretrained(\"ddpm_mnist_baseline/\")\n",
    "baseline_model.to(device)\n",
    "baseline_model.eval()"
   ],
   "id": "c3160ff13a8ff4a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koopman Operator initialized with 2048 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet2DModel(\n",
       "  (conv_in): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): AttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Attention(\n",
       "          (group_norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-2): 3 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Attention(\n",
       "          (group_norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock2D(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Attention(\n",
       "        (group_norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (to_out): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "69b3b3e8-09be-4d8d-b124-94ba2c6f0a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T23:04:35.708066Z",
     "start_time": "2025-11-18T23:04:22.394754Z"
    }
   },
   "source": [
    "train_dataloader = get_dataloader(config)\n",
    "run_full_dashboard(model, baseline_model, train_dataloader, config, device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Spectral Analysis ---\n",
      "--- Generating Koopman Modes ---\n",
      "--- Generating Latent Space Comparison ---\n",
      "Extracting Koopman latents...\n",
      "Extracting Baseline latents...\n",
      "Running t-SNE...\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
